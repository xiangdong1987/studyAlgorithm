# 经验总结
1. 抛开所有的业务逻辑和功能的外壳，我们做的都是对数据的存储和计算。
    * 存储：数据结构
    * 计算：算法
2. 索引需求的定义
    * 功能性考虑：
        * 格式化索引数据和非格式化数据
        * 数据是静态还是动态
        * 存储在内存还是硬盘
        * 单值查询还是区间查询
        * 单关键字查询还是多关键字查询
    * 非功能性考虑：
        * 空间使用
        * 查询效率和维护成本
3. 并行执行：对于mapReduce直接先拆分，再并行。优化可以通过先用拓扑算法分先后顺序，在执行根据依赖关系先后顺序并行执行。
# 实践总结
* redis
    * list 列表：
        * 压缩列表：对于数据量小的可以采取压缩列表保存
            * 列表的单个数据不超过64字节
            * 列表数据少于512个
        * 双向循环链表
            * 使用双向链表，redis为了更好的使用链表，定义了一个链表的结构体，记录一些常用的属性
    * hash字典：
        * 压缩列表：同上
        * 散列表：利用的是murmurHash函数进行哈希（非加密的哈希函数）
            * 如何动态扩容
                1. 先申请一个大于原来存储空间的空间
                2. 在插入新数据时，直接插入新空间，并将老空间的一个数据也插入新空间，随着新数据的插入，老数据一点点的被迁移
                3. 查询，先查新的再查旧的散列表
    * set集合
        * 有序数组：
            1. 存储的数据都是整数
            2. 集合元素少于512个
        * 散列表
    * sortset有序集合
        * 跳表
        * 压缩表
            1. 所有数据小于64字节
            2. 元素个数小于128个
    * 数据持久化
        * aof：重新构建
        * rdb：保存数据结构
* 搜索引擎
    * 搜集：爬虫
        1. 爬取网页需要一个队列，可以利用link.bin来做队列，头部取尾部加入
        2. 网页判重可以利用布隆过滤器来做判重bloom_filter.bin暂用内存小可以隔几个小时更新一次到硬盘
        3. 原始网页存储doc_raw.bin 通过某种数据结构保存如：id  + length + content + 分隔符
        4. 编号要是唯一的，所以做一个id生成器doc_id.bin
    * 分析：内容抽取，分词，构建临时索引，计算pageRank
        1. 抽取内容
        2. 分词创建临时索引创建分词+文档id的关系 temp_index.bin 和term_id.bin
    * 索引：根据分析得到的结果构建索引，倒排索引
        1. 通过临时索引构建倒排索引，多路归并排序
        2. 需要两个文件index.bin(最后的倒排索引)和term_offset.bin(单词在倒排索引的偏移量)
    * 查询：响应用户请求，根据搜索条件返回倒排内容
        1. 用户输入查询内容对内容进行分词，获取n个分词，根据分词查找倒排索引，找到对应的k个doc_id
        2. 根据doc_id的出现次数排序，将结果分页显示给用户
    * pageRank：一种页面排行算法，根据页面的外链和其他网站链接本页面的多少来计算
    * tf-idf：
        * tf(term-frequency)词频：词语在文档中出现的概率
        * idf(inverse-document-frequency)逆文本率：语料库总数/包含该词的语料数
    * 列子：有很多不同的数学公式可以用来计算tf-idf。这边的例子以上述的数学公式来计算。词频（tf）是一词语出现的次数除以该文件的总词语数。假如一篇文件的总词语数是100个，而词语“母牛”出现了3次，那么“母牛”一词在该文件中的词频就是3/100=0.03。而计算文件频率（IDF）的方法是以文件集的文件总数，除以出现“母牛”一词的文件数。所以，如果“母牛”一词在1,000份文件出现过，而文件总数是10,000,000份的话，其逆向文件频率就是lg（10,000,000 / 1,000）=4。最后的tf-idf的分数为0.03 * 4=0.12。
